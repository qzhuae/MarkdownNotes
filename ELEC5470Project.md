# ELEC5470 Project Notes

Topic: Convexity in Time Series Analysis
Overleaf: https://www.overleaf.com/project/5c05360907ab3829aff61451

## Difference between Regression and Time Series Analysis

I found this from two Quora questions I believe.

## References

http://stefanos.web.unc.edu/

https://www.sciencedirect.com/science/article/pii/S0263224117301458

http://www.optimization-online.org/DB_HTML/2007/09/1791.html

https://www.cs.huji.ac.il/~shais/papers/OLsurvey.pdf

https://www.quora.com/Why-is-Convex-Optimization-such-a-big-deal-in-Machine-Learning

parameter estimation in linear-Gaussian time series

http://users.cms.caltech.edu/~venkatc/vc_phdthesis.pdf

http://www.stat.cmu.edu/~ryantibs/convexopt/syllabus.pdf

https://sdsi.stanford.edu/sites/default/files/jure_leskovec_ticc-sdsi-nov17.pdf

http://stanford.edu/~boyd/papers/pdf/network_lasso.pdf

www.princeton.edu/~amirali/Public/Teaching/ORF523/S17/ORF523_S17_Lec17_guest.pdf

http://www.statsoft.com/textbook/time-series-analysis

https://web.stanford.edu/~boyd/papers/pdf/rt_cvx_sig_proc.pdf

https://web.stanford.edu/~boyd/papers/pdf/sig_proc_mag.pdf

http://www.optimization-online.org/DB_FILE/2007/09/1779.pdf

http://www.maths.lth.se/matstat/kurser/fms110mas222/10state_space_estimation.pdf

http://www.princeton.edu/~amirali/Public/Teaching/ORF523/S16/ORF523_S16_Lec17_guest.pdf

http://users.cms.caltech.edu/~venkatc/vc_phdthesis.pdf

https://www.bing.com/search?q=time+series+analysis+with+convex+optimization&qs=PF&cvid=8dac0340919d40b8a3c0cb72d4c56c30&refig=4cb30562c9054461e3bdfcf8996a111b&cc=US&setlang=en-US&first=29&FORM=PORE

Online Convex Analysis

https://www.google.com.hk/search?q=convexity+in+kalman+filtering&rlz=1C1GCEB_enHK820HK820&oq=convexity+in+kalman+filtering&aqs=chrome..69i57.4080j0j7&sourceid=chrome&ie=UTF-8

https://web.stanford.edu/~boyd/papers/pdf/rt_cvx_sig_proc.pdf

https://web.stanford.edu/~boyd/papers/pdf/sig_proc_mag.pdf

http://www.statsoft.com/textbook/time-series-analysis#exponential

Seasonality or Trend Estimation

## Convexity in Kalman Filtering 

__Gaussian Process Regression__

## Convexity in Value at Risk
Looks pretty difficult and I'm not really interested in.

## Convexity in Bayesian Optimization

With relationship to different distributions

## Convexity in Gaussian Process Regression


## Electronic Trading
https://signalprocessingsociety.org/blog/financial-signal-processing-and-machine-learning-electronic-trading

https://era.library.ualberta.ca/items/4a6607d9-516e-4580-8b64-0ef18f47f1c4/view/7d7bc015-e452-4ce3-9405-0dedcfc78587/Balazs_Gabor_201609_PhD.pdf

## Dec 4

http://www.ece.ust.hk/~palomar/MAFS6010R_lectures/week%2007/slides_times_series_modeling.pdf

https://www.google.com.hk/search?q=Gaussian+Process+Regression&rlz=1C1GCEB_enHK820HK820&oq=Gaussian+Process+Regression&aqs=chrome..69i57j0l5.4079j0j7&sourceid=chrome&ie=UTF-8

https://en.wikipedia.org/wiki/Kalman_filter

https://www.google.com.hk/search?q=dirichlet+process+regression&rlz=1C1GCEB_enHK820HK820&oq=dirichlet+process+regression&aqs=chrome..69i57j0l5.3135j0j7&sourceid=chrome&ie=UTF-8

https://www.google.com.hk/search?q=Convex+optimization+in+gaussian+process+regression&rlz=1C1GCEB_enHK820HK820&oq=Convex+optimization+in+gaussian+process+regression&aqs=chrome..69i57.9615j1j7&sourceid=chrome&ie=UTF-8

http://www.robots.ox.ac.uk/~mosb/public/pdf/115/Osborne%20et%20al.%20-%202009%20-%20Gaussian%20processes%20for%20global%20optimization.pdf

https://cs.stanford.edu/~quocle/LeSmoCan05.pdf

https://stats.stackexchange.com/questions/342287/is-the-mle-problem-for-gaussian-process-regression-convex

http://www.gaussianprocess.org/gpml/chapters/RW2.pdf


https://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf


https://www.google.com.hk/search?q=trend+and+seasonality+estimation+in+convex+optimization&rlz=1C1GCEB_enHK820HK820&oq=trend+and+seasonality+estimation+in+convex+optimization&aqs=chrome..69i57.7903j0j7&sourceid=chrome&ie=UTF-8

https://geography.wr.usgs.gov/InnovationCenter/2014/docs/gecco-17-hyperstl-2017-04-19.pdf

https://www.researchgate.net/publication/303245487_Can_nuclear_norm_penalization_enhance_Prony's_method

https://www.researchgate.net/post/What_is_the_relation_between_Kalman_filtering_and_Gaussian_process_regression

https://www.researchgate.net/post/What_is_the_relation_between_Kalman_filtering_and_Gaussian_process_regression

https://www.researchgate.net/post/What_are_other_modern_alternatives_to_Markov_Chain_models

https://www.semanticscholar.org/paper/The-Kernel-Kalman-Rule-Efficient-Nonparametric-with-Gebhardt-Kupcsik/2b85c85b3b72220b178cc62fa07a35afad28798c

https://arxiv.org/pdf/1504.05994.pdf

https://www.google.com.hk/search?q=convex+regression+models&rlz=1C1GCEB_enHK820HK820&oq=convex+regression+models&aqs=chrome..69i57.2719j0j7&sourceid=chrome&ie=UTF-8

https://arxiv.org/pdf/1105.1924.pdf

http://www.stat.columbia.edu/~bodhi/Talks/NPCvxReg.pdf

https://www.google.com.hk/search?q=Convex+and+Non-convex+regression&rlz=1C1GCEB_enHK820HK820&oq=Convex+and+Non-convex+regression&aqs=chrome..69i57.5263j1j7&sourceid=chrome&ie=UTF-8

https://trimestres-lmb.univ-fcomte.fr/IMG/pdf/s_chretien_6_mai_2014.pdf

http://www.ee.umn.edu/users/georgiou/papers/GL3.pdf

http://www.jmlr.org/papers/volume12/hannah11a/hannah11a.pdf

https://en.wikipedia.org/wiki/Kriging

https://www.cs.toronto.edu/~duvenaud/talks/intro_bq.pdf

https://core.ac.uk/download/pdf/6237204.pdf

## Summary of Finished Readings

https://web.stanford.edu/~boyd/papers/pdf/cvx_applications.pdf
Shows one example of time series regression auto-regressive, with tilted l1 loss

https://cs.nyu.edu/~mohri/talks/MIT2017.pdf
Online Learning for Time Series Prediction
No distributional assumptions, Regret Minimization

https://dzone.com/articles/convex-regression-model
Convex Regression Model

https://www.researchgate.net/project/Convex-analysis-for-time-series
General Topic on using convex analysis technique on Time Series Estimation

http://linstat2018.put.poznan.pl/Abs/Gajdos.pdf
This is just an abstract, but it shows something I really want to do
Involve Kriging, and stochastic processes

http://www.math.ucla.edu/~eryu/papers/ryu_thesis_page_removed-augmented.pdf
This is really fun stuff about stochastic optimization

https://www.quora.com/Which-is-more-useful-for-data-science-regression-or-time-series-models
Regression vs. Time Series, TS more simple forecast, Regression more input

## Some Questions to Answer
- What is the difference between Time Series Analysis and Time Series Estimation

## Actual Content

possible time series forecasting models ARIMA, ARMA, Holt-Winter, Hybrid modelling, UCM

In time series sequence matters but not in regression. 

`univariate time series`
* Secular Trend or General Trend
* Seasonal Movements
* Cyclical Movements
* Irregular Fluctuations

way of looking at the trend is to draw mean production line and then check if new data points are trying to come near the mean? If yes, there is no trend. 

Suppose that the observed series is  _x__(t)_, for  _t_=1,2,…,_n_

-   For a linear trend, use  _t_  (the time index) as a predictor variable in a regression.
    
-   For a quadratic trend, we might consider using both  _t_  and  _t_2.
    
-   For quarterly data, with possible seasonal (quarterly) effects, we can define indicator variables such as  $S_j  = 1$ if observation is in quarter  _j_  of a year and 0 otherwise. There are 4 such indicators.

RMSE or R Square can be used for model validation. I would also like to mention that R square is a comparison parameter to know 'how better regression is fitting data points compare to simple average”.

https://machinelearningstories.blogspot.com/2018/07/anomaly-detection-anomaly-detection-by.html


http://machinelearningstories.blogspot.com/2016_11_01_archive.html 
[Market Basket Analysis]


https://arxiv.org/pdf/1302.6613.pdf [An Introductory Study on Time Series Modeling and Forecasting]

http://machinelearningstories.blogspot.com/2016/08/time-series-and-fitting-regression-on.html
One difference from standard linear regression is that the data are not necessarily independent and not necessarily identically distributed. One defining characteristic of time series is that this is a list of observations where the ordering matters. Ordering is very important because there is dependency and changing the order could change the meaning of the data.

> From Stan, Look at Stationarity, Autocorrelation, AR process

### [Most Important Source So Far] 
https://trimestres-lmb.univ-fcomte.fr/IMG/pdf/s_chretien_6_mai_2014.pdf

Most standard case of ARMA fluctuations
- estimate `trend`
- estimate `seasonality`
- estimate `ARAM model`

Difficult because:
- ARMA(p,q) model estimation via log-likelihood is non-convex optimization problem, not to speak about model selection
- Estimating a sum of damped exponentials via least-squares is a non-convex optimization problem, and the same problem holds for model order selection (number of exponential)
- Trends are sometimes subject to abrupt changes in the 0th, 1th, 2th derivative, whose number and location are hard to estimate since they are often recast as solutions to non-convex optimization problems

`Sparsity promoting penalizations of the least-square criterion  and allow simultaneous model estimation and model order selection`

Trend estimation problem: `l1-trend filtering`, by S.-J. Kim, K. Koh, S. Boyd, and D. Gorinevsky, SIAM Review, problems and techniques section, 51(2):339360, May 2009.,

Seasonality estimation problem: `Prony's method and its recent enhanced versions`


ARMA estimation problem: `The subspace method approach via the state space model for ARMA estimation`, Larimore, Proceedings of the 1983 American Control Conference 2.

**Background on sparsity-promoting penalized least-squares**

$y = X\beta + \epsilon$, this has huge number of covariates.

with p >> n, p dimension of  $\beta$.  In the case, in gene expression analysis, image de-noisng with dictionaries, graphical models.

To solve estimation problem:
Compare all sparse enough regression models using criterion like AIC, BIC, MDL
The only known method in this case is enumeration, this might be too complex

`Lasso` When one lets the relaxation parameter $\lambda$ go from a sufficiently large value to zero, the coef are shrinked and most of them are set to zero.

It was possible to prove that exact recovery of support and sign pattern of \beta can be recovered with high probability in the case of gaussian noise.

Main assumptions on the `design matrix` are 
- incoherence: some condition on $\mu(X) = \max |X_j^tX_{j'}| \leq \frac{C_\mu}{\log(p)}$
- Restricted Isometry: $\forall T, |T| \leq 2s$, $1 - \delta \leq \sigma_{min} \leq \sigma_{max} \leq 1 + \delta$.

Incoherence implies a sort of relaxed restricted isometry property (I don't get this)

Sparsity => Low-rank matrix 

Convex surrogate nuclear norm, [Remember something in class about, this relaxed solution being the same as low rank solution, I think it is proved by duality]

**Trend Estimation**
Trend can be locally estimated using polynomial. This polynomial is sometimes subject to abrupt changes over a longer period of observations. 

Based on Lasso, KIM, Koh, Boyd proposed l-1 trend filtering

**Seasonality Estimation**


**ARMA Estimation**
- Many criteria which are described in standard textbooks are non-convex and the optimization routines are thus not guaranteed to provide the desired global optimum. 
- Model order selection is a combinatorial optimization when addressed using penalization approaches such as AIC or BIC.

Equivalent Criteria by Van Overschee and DeMoor
- Canonical variate analysis in identification filtering and adaptive control
- N4SID: Subspace algorithms for the identification of combined deterministic-stochastic systems
- A unifying theorem for three subspace system identification algorithms, Van Overschee and B. De Moor

**Anomaly Detection & Anomaly detection by distance and density based clustering algorithms**
https://machinelearningstories.blogspot.com/2018/07/anomaly-detection-anomaly-detection-by.html


## List of papers read, minimum 8





## Some Points to be made
- Lack of metric to measure across datasets
- Robustness, emsemble learning over multiple cost function and multiple models
- Loss, sparsity to make things not overfitting
- Optimization Techniques

## Some Future Readings

[Pattern Characterization/Data Mining] http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.87.268&rep=rep1&type=pdf

[Temporal Dependence in Time Series] https://www.computer.org/csdl/proceedings/dsaa/2016/5206/00/07796911.pdf

[]
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEwNDQ4NzYzNDAsMTc1ODY4NDkxMCwtND
E5NjcyNTI2LDE4NDIxOTE4NDksLTIwOTM5ODY0MzIsMjA3MTEz
MTgxMiwxNzE0NzU3ODI5LC0yMDg2OTE1NzQsMzE1MTE2Nzg3LD
g3ODcwNDQ0MywtODgxOTQwMDc1LDEwNDY4MjAyNiwxNjM2MTE2
NDU1LDEwNDYzMDUwODUsMTM0ODQzMDMzLC0xODQzMDkxODU4LD
cwOTk1OTk0OSwyNjA3MTc4MDgsNzUyNTA4NTE0LC0xNTcwMjIy
MTk0XX0=
-->