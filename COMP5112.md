


> Written with [StackEdit](https://stackedit.io/).
# COMP5112 Parallel Programming

## Introduction to Parallel Computing


From 1986 – 2002, microprocessors were speeding like a rocket, increasing in performance an average of 50% per year. Since then, it’s dropped to about 20% increase per year.

[An intelligent solution] Instead of designing and building faster microprocessors, put multiple processors on a single integrated circuit.

Why do we need ever-increasing performance?
Computational power is increasing, but so are our computation problems and needs. Problems we never dreamed of have been solved, such as decoding the human genome. More complex problems are still waiting to be solved. Such as,  Climate Modeling, Protein folding, Drug discovery, Energy Research, Data analysis.

Up to now, performance increases have been attributable to increasing density of transistors. But there are inherent problems:
- Denser transistors -> faster processors
- Faster processors -> increased power consumption
- Increased power consumption -> increased heat
- Increased heat -> unreliable processors

Solution is to move away from single-core systems to multicore processors. "core" = central processing unit (CPU) by introducing parallelism

We can rewrite serial programs so that they are parallel. Write translation programs that automatically convert serial programs into parallel programs. But this is difficult to do and success has been limited.

More problems with translation: 
- Some coding constructs can be recognized by an automatic program generator, and converted to a parallel construct.
- However, it is likely that the results will be a very inefficient program.
- Sometimes the best parallel solution is to step back and devise an entirely new algorithm.

Example: compute n values and add them together
Serial Solution:

    sum = 0;
    for (i = 0; i < n; i ++){
		x = Compute_next_value();
		sum += x;
	}

Suppose we have p cores, p << n. Each core performs a partial sum of approximately n/p values.

    my_sum = 0;
    my_first_i = ;
    my_last_i = ;
    for (my_i = my_first_i; my_i < my_last_i; my_i++){
	    my_x = Compute_next_value();
	    my_sum += my_x;}

After each core completes execution of the code, a private variable my_sum contains the sum of the values computed by its calls to Compute_next_value(). Once all the cores are done computing their private my_sum, they form a global sum by sending results to a designated “master” core which adds the final result.

    If (I'm the master core){
	    sum = my_x;
	    for each core other than myself{
		    receive value from core;
		    sum += value;
		}
	} else {
		send my_x to the master;
	}


<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE0MzI4MzUyNjAsMTM2NDM2NzkzNF19
-->